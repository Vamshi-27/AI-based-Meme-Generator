import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import clip
from PIL import Image
import os
from torch.utils.data import DataLoader
from src.data_preparation import MemeDataset

class MemeCaptionModel:
    def __init__(self, device="cuda" if torch.cuda.is_available() else "cpu"):
        self.device = torch.device(device)
        
        # Load models
        self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
        self.gpt2_model = GPT2LMHeadModel.from_pretrained("gpt2").to(self.device)

    def get_image_features(self, image):
        """
        Extract image features using CLIP.
        """
        image_input = self.clip_preprocess(image).unsqueeze(0).to(self.device)
        with torch.no_grad():
            image_features = self.clip_model.encode_image(image_input)
        return image_features

    def train(self, data_loader, num_epochs=5):
        """
        Training logic to fine-tune GPT-2 on captions generated by CLIP.
        """
        optimizer = torch.optim.Adam(self.gpt2_model.parameters(), lr=0.001)

        for epoch in range(num_epochs):
            total_loss = 0
            print(f"\n=== Epoch {epoch + 1}/{num_epochs} ===")
            
            for batch_idx, (image_path, caption) in enumerate(data_loader):
                try:
                    # Load image and extract features
                    image = Image.open(image_path).convert("RGB")
                    image_features = self.get_image_features(image)

                    # Prepare the input prompt for GPT-2
                    text_input = f"Image features: {image_features.sum().item()}. Caption: "
                    input_ids = self.gpt2_tokenizer.encode(text_input, return_tensors="pt").to(self.device)
                    labels = self.gpt2_tokenizer.encode(caption, return_tensors="pt").to(self.device)

                    # Forward pass and compute loss
                    outputs = self.gpt2_model(input_ids, labels=labels)
                    loss = outputs.loss
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()

                    # Print progress for each batch
                    if batch_idx % 10 == 0:
                        print(f"Batch {batch_idx}/{len(data_loader)} - Loss: {loss.item():.4f}")
                except Exception as e:
                    print(f"Error processing batch {batch_idx}: {e}")

            avg_loss = total_loss / len(data_loader)
            print(f"Epoch {epoch + 1} completed. Average Loss: {avg_loss:.4f}")

    def save_model(self, path):
        torch.save(self.gpt2_model.state_dict(), path)
        print(f"Model saved successfully at {path}")
